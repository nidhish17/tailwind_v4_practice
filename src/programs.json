{
    "program1": "data = fetch_california_housing(as_frame=True)\nhousing_data = data.frame\n\nnumerical_features = housing_data.select_dtypes(include=[np.number]).columns\n\n# Histogram plot for all the numerical features\nplt.figure(figsize=(15,10))\ncounter = 0\nfor i, feature in enumerate(numerical_features):\n    plt.subplot(4, 4, i+1)\n    sns.histplot(housing_data[feature], kde=True, bins=30)\n    plt.title(feature)\nplt.show()\n\n# box plots\nplt.figure(figsize=(15,10))\nfor idx, feature in enumerate(numerical_features):\n    plt.subplot(3, 3, idx+1)\n    sns.boxplot(housing_data[feature], color=\"crimson\")\n    plt.title(feature)\nplt.show()\n#%%\n# identifying outliers\noutliers_summary = {}\n\nfor feature in numerical_features:\n    q1 = housing_data[feature].quantile(.25)\n    q3 = housing_data[feature].quantile(.75)\n    iqr = q3 - q1\n\n    lower_bound = (q1 - 1.5) * iqr\n    upper_bound = (q3 + 1.5) * iqr\n\n    outliers = housing_data[(housing_data[feature] < lower_bound) | (housing_data[feature] > upper_bound)]\n    outliers_summary[feature] = len(outliers)\n\nprint(outliers_summary)\n#%%\nhousing_data.describe()",
    "program2": "california_data = fetch_california_housing(as_frame=True)\ndata = california_data.frame\n\ncor_mat = data.corr()\n\nplt.figure(figsize=(15, 10))\n\nsns.heatmap(cor_mat, annot=True, cmap=\"coolwarm\")\nplt.show()\n\n# pair plot\nsns.pairplot(data, diag_kind=\"kde\")\nplt.show()",
    "program3": "iris = load_iris()\ndata = iris.data\nlabels = iris.target\nlabel_names = iris.target_names\niris_df = pd.DataFrame(data, columns=iris.feature_names)\n#%%\npca = PCA(n_components=2)\ndata_reduced = pca.fit_transform(data)\nreduced_df = pd.DataFrame(data_reduced, columns=[\"principal_component_1\", \"principal_component_2\"])\nreduced_df[\"label\"] = labels\n\n#%%\nfrom bokeh.colors.named import colors\n\n# plot the reduced data\nplt.figure(figsize=(15, 10))\nfor idx, label in enumerate(np.unique(labels)):\n    plt.scatter(\n        reduced_df[reduced_df['label'] == label]['principal_component_1'],\n        reduced_df[reduced_df[\"label\"] == label][\"principal_component_2\"],\n        label=label_names[label],\n    )\n\nplt.grid()\nplt.legend()\nplt.title(\"iris Dataset\")\nplt.show()",
    "program4": "data = read_csv(\"https://tailwindv4.netlify.app/data.csv\")\ndata\n\n\n#%%\ndef find_s_algo():\n    features = data.columns[:-1]\n    print(features)\n    y_label = data.columns[-1]\n    print(y_label)\n    hypothesis = [\"?\" for _ in features]\n    print(hypothesis)\n\n    for idx, row in data.iterrows():\n        if row[y_label] == \"yes\":\n            for i, value in enumerate(row[features]):\n                if hypothesis[i] == \"?\" or hypothesis[i] == value:\n                    hypothesis[i] = value\n                else:\n                    hypothesis[i] = \"?\"\n\n    return hypothesis\n\nfind_s_algo()",
    "program7": {
        "imports": "from sklearn.datasets import fetch_california_housing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import make_pipeline",
        "linear_regression": "def linear_regression_california():\n    housing = fetch_california_housing(as_frame=True)\n    X = housing.data[[\"AveRooms\"]]\n    y = housing.target\n\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n\n    model = LinearRegression()\n    model.fit(x_train, y_train)\n\n    y_pred = model.predict(x_test)\n\n    plt.scatter(x_test, y_test, color=\"blue\", label=\"Actual\")\n    plt.plot(x_test, y_pred, color=\"red\", label=\"predicted\")\n    plt.legend()\n    plt.show()",
        "polynomial_regression": "def polynomial_regression():\n    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n    column_names = [\"mpg\", \"cylinders\", \"displacement\", \"sdf\", \"sdfsdf\", \"dfg\", \"ghf\", \"ddfg\"]\n\n    data = pd.read_csv(url, sep=\"\\s+\", names=column_names, na_values=\"?\")\n    data.dropna(inplace=True)\n\n\n    x = data[\"displacement\"].values.reshape(-1, 1)\n    y = data[\"mpg\"].values\n\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)\n\n    model = make_pipeline(PolynomialFeatures(degree=2), StandardScaler(), LinearRegression())\n\n    model.fit(x_train, y_train)\n\n    y_pred = model.predict(x_test)\n\n    plt.scatter(x_test, y_test, color=\"blue\", label=\"Actual\")\n    plt.scatter(x_test, y_pred, color=\"red\", label=\"Predicted\")\n    plt.legend()\n    plt.show()"
    },
    "program8": {
        "imports": "import matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree",
        "code": "data = load_breast_cancer()\nx = data.data\ny = data.target\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)\n\nmodel = DecisionTreeClassifier(random_state=69)\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\npred_class = \"Benign\" if model.predict([x_test[0]]) == 1 else \"Malignant\"\nprint(f\"Predicted: {pred_class}\")\n\nplt.figure(figsize=(15,10))\nplot_tree(model, filled=True, feature_names=data.feature_names.tolist(), class_names=data.target_names.tolist())\nplt.title(\"Decision tree\")\nplt.show()\n\n\n"
    },
    "program9": "data = fetch_olivetti_faces(shuffle=True, random_state=69)\nx = data.data\ny = data.target\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)\nmodel = GaussianNB()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nfig, axes = plt.subplots(3, 5, figsize=(6, 6))\nfor ax, img, lbl, pred in zip(axes.ravel(), x_test, y_test, y_pred):\n    ax.imshow(img.reshape(64, 64), cmap=\"gray\")\n    ax.axis(\"off\")\n    ax.set_title(f\"T: {lbl}, P: {pred}\")\nplt.show()\n\n",
    "jic": "https://raw.githubusercontent.com/Manikanta-484/ML-lab/refs/heads/main/lab{num}.py"
}
